{"id": "0422768c-b6b0-4ecc-b03f-4aeea2d391f4", "code": "# initial_program.py\n# This file is evolved by AlphaEvolve\n# ONLY update_rho (and helpers) may be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2, K0=0):\n    \"\"\"\n    Step size sequence tau_k.\n\n    Fully C1-safe:\n    - tau_k >= 0 for all k\n    - summable for p > 1\n    - depends ONLY on k and fixed constants\n    \"\"\"\n    if k < K0:\n        return 0.0\n    return c / ((k - K0 + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule (C1-safe template).\n\n    This implementation STRICTLY satisfies:\n    - Strategy3 / Condition C1\n    - Checker-friendly mathematical form\n    \"\"\"\n\n    # Step size (independent of residuals)\n    t = tau(k, c=c, p=p)\n\n    # Direction selection (logic only)\n    if r_norm > mu * max(s_norm, eps):\n        # Case (a): rho_k * (1 + tau_k)\n        return rho * (1.0 + t), t, \"mul\"\n\n    if s_norm > mu * max(r_norm, eps):\n        # Case (b): rho_k / (1 + tau_k)\n        return rho / (1.0 + t), t, \"div\"\n\n    # Case (c): rho_k\n    return rho, t, \"keep\"\n", "language": "python", "parent_id": null, "generation": 0, "timestamp": 1770108139.680328, "iteration_found": 0, "metrics": {"combined_score": 0.07665244068848408, "metrics": {"converged": true, "iters": 13, "combined_score": 0.07665244068848408}, "artifacts": {"status": "CONVERGED", "iterations": 13, "eval_time": "33.853s"}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"island": 0}, "prompts": null, "artifacts_json": null, "artifact_dir": null, "embedding": null}