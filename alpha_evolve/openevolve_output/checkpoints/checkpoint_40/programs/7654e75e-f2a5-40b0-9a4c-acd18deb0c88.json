{"id": "7654e75e-f2a5-40b0-9a4c-acd18deb0c88", "code": "# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence with faster initial decay.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    # Add a term to accelerate initial decay\n    return c / ((k + 1.0 + 0.1 * np.sqrt(k + 1.0)) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with dynamic threshold.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n    \n    # Dynamic threshold: more sensitive early, more stable later\n    # As k increases, dynamic_mu decreases towards mu\n    dynamic_mu = mu * (1.0 + 2.0 / (k + 2.0))\n    \n    # Compute imbalance ratio\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Adjust step size: more aggressive when ratio is large, but bounded\n    # Also, reduce adjustment as iterations progress\n    scale = min(ratio / dynamic_mu, 2.0)\n    # Weight for adjustment decreases with k\n    weight = 1.0 / (1.0 + 0.1 * k)\n    adjusted_t = t * (1.0 + weight * scale)\n    \n    if r_norm > dynamic_mu * max(s_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_norm > dynamic_mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Auxiliary scalar: track the dynamic threshold\n    aux = dynamic_mu\n    \n    return new_rho, aux, mode\n", "language": "python", "parent_id": "dd721bc1-d8f0-4b43-b0a3-ce00199ed36a", "generation": 2, "timestamp": 1770112575.673426, "iteration_found": 21, "metrics": {"combined_score": 0.07670413431293388, "metrics": {"converged": true, "iters": 13, "combined_score": 0.07670413431293388}, "artifacts": {"status": "CONVERGED", "iterations": 13, "eval_time": "42.868s"}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 50 lines with 49 lines\nChange 2: Replace 10 lines with 11 lines", "parent_metrics": {"combined_score": 0.08282272821092926, "metrics": {"converged": true, "iters": 12, "combined_score": 0.08282272821092926}, "artifacts": {"status": "CONVERGED", "iterations": 12, "eval_time": "32.520s"}}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert software developer tasked with iteratively improving a codebase.\nYour goal is to maximize the FITNESS SCORE while exploring diverse solutions across feature dimensions.\nThe system maintains a collection of diverse programs - both high fitness AND diversity are valuable.", "user": "# Current Program Information\n- Fitness: 0.0828\n- Feature coordinates: \n- Focus areas: - Fitness improved: 0.0768 \u2192 0.0828\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 10 lines with 12 lines\nChange 2: Replace 46 lines with 46 lines\n- Metrics: combined_score: 0.0768, metrics: {'converged': True, 'iters': 13, 'combined_score': 0.07675777142078459}, artifacts: {'status': 'CONVERGED', 'iterations': 13, 'eval_time': '29.074s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 2\n- Changes: Change 1: Replace 10 lines with 12 lines\nChange 2: Replace 42 lines with 46 lines\n- Metrics: combined_score: 0.0768, metrics: {'converged': True, 'iters': 13, 'combined_score': 0.07675777142078459}, artifacts: {'status': 'CONVERGED', 'iterations': 13, 'eval_time': '24.427s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 1\n- Changes: Change 1: Replace 15 lines with 29 lines\n- Metrics: combined_score: 0.0828, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08282272821092926}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '32.520s'}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.0828)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    # Compute imbalance ratio\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Adjust step size based on ratio, but keep it bounded\n    # Use a moderate scaling: min(ratio / mu, 1.5) to prevent excessive updates\n    scale = min(ratio / mu, 1.5)\n    adjusted_t = t * (1.0 + 0.5 * scale)  # Increase t by up to 50% when ratio is large\n    \n    if r_norm > mu * max(s_norm, eps):\n        # Use adjusted step size for update\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: include information about adjustment\n    aux = adjusted_t\n\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0828), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08282272821092926}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '32.520s'})\n\n### Program 2 (Score: 0.0768)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence with faster initial decay.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    # Add a small constant to denominator to prevent division by zero\n    # This gives faster decay initially\n    return c / ((k + 1.0 + 0.1 * np.sqrt(k + 1.0)) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with dynamic threshold.\n\n    The threshold adapts over iterations to be more responsive early on.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n    \n    # Dynamic threshold that diminishes with iterations\n    # This makes the algorithm more sensitive early, and more stable later\n    dynamic_mu = mu * (1.0 + 2.0/(k + 1.0))\n    \n    # Direction logic with dynamic threshold\n    if r_norm > dynamic_mu * max(s_norm, eps):\n        # More aggressive update when residuals are very imbalanced\n        # Use a larger step when the ratio is high\n        ratio = r_norm / max(s_norm, eps)\n        # Scale step size by log(ratio) but clip to avoid extreme values\n        scale = min(max(np.log(ratio), 0.1), 2.0)\n        new_rho = rho * (1.0 + t * scale)\n        mode = \"mul\"\n\n    elif s_norm > dynamic_mu * max(r_norm, eps):\n        ratio = s_norm / max(r_norm, eps)\n        scale = min(max(np.log(ratio), 0.1), 2.0)\n        new_rho = rho / (1.0 + t * scale)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0768), Performs well on metrics ({'converged': True, 'iters': 13, 'combined_score': 0.07675777142078459}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 13, 'eval_time': '24.427s'})\n\n### Program 3 (Score: 0.0768)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence with faster initial decay.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    # Add a small constant to denominator to prevent division by zero\n    # This gives faster decay initially\n    return c / ((k + 1.0 + 0.1 * np.sqrt(k + 1.0)) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with dynamic threshold.\n\n    The threshold adapts over iterations to be more responsive early on.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n    \n    # Dynamic threshold that diminishes with iterations\n    # This makes the algorithm more sensitive early, and more stable later\n    dynamic_mu = mu * (1.0 + 2.0/(k + 1.0))\n    \n    # Direction logic with dynamic threshold\n    if r_norm > dynamic_mu * max(s_norm, eps):\n        # More aggressive update when residuals are very imbalanced\n        # Use a larger step when the ratio is high\n        ratio = r_norm / max(s_norm, eps)\n        # Scale step size by log(ratio) but clip to avoid extreme values\n        scale = min(max(np.log(ratio), 0.1), 2.0)\n        new_rho = rho * (1.0 + t * scale)\n        mode = \"mul\"\n\n    elif s_norm > dynamic_mu * max(r_norm, eps):\n        ratio = s_norm / max(r_norm, eps)\n        scale = min(max(np.log(ratio), 0.1), 2.0)\n        new_rho = rho / (1.0 + t * scale)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0768), Performs well on metrics ({'converged': True, 'iters': 13, 'combined_score': 0.07675777142078459}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 13, 'eval_time': '29.074s'})\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0768)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence with faster initial decay.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    # Add a small constant to denominator to prevent division by zero\n    # This gives faster decay initially\n    return c / ((k + 1.0 + 0.1 * np.sqrt(k + 1.0)) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with dynamic threshold.\n\n    The threshold adapts over iterations to be more responsive early on.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n    \n    # Dynamic threshold that diminishes with iterations\n    # This makes the algorithm more sensitive early, and more stable later\n    dynamic_mu = mu * (1.0 + 2.0/(k + 1.0))\n    \n    # Direction logic with dynamic threshold\n    if r_norm > dynamic_mu * max(s_norm, eps):\n        # More aggressive update when residuals are very imbalanced\n        # Use a larger step when the ratio is high\n        ratio = r_norm / max(s_norm, eps)\n        # Scale step size by log(ratio) but clip to avoid extreme values\n        scale = min(max(np.log(ratio), 0.1), 2.0)\n        new_rho = rho * (1.0 + t * scale)\n        mode = \"mul\"\n\n    elif s_norm > dynamic_mu * max(r_norm, eps):\n        ratio = s_norm / max(r_norm, eps)\n        scale = min(max(np.log(ratio), 0.1), 2.0)\n        new_rho = rho / (1.0 + t * scale)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n### Program D2 (Score: 0.0767)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > mu * max(s_norm, eps):\n        new_rho = rho * (1.0 + t)\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        new_rho = rho / (1.0 + t)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: independent of residuals for C1 safety\n    aux = t\n\n    return new_rho, aux, mode\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0761, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n    \n    # Compute residual ratio for adaptive step adjustment\n    # To avoid division by zero, use eps\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Adaptive step scaling: when ratio is far from 1, use larger step\n    # But ensure it's bounded to maintain summability\n    scale = min(2.0, max(0.5, ratio))\n    adaptive_t = t * scale\n\n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > mu * max(s_norm, eps):\n        new_rho = rho * (1.0 + adaptive_t)\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        new_rho = rho / (1.0 + adaptive_t)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: track residual ratio for monitoring\n    aux = ratio\n\n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 2 (Score: 0.0766, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=2.5,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    # Compute residual ratio for more nuanced update\n    if r_norm > mu * max(s_norm, eps):\n        # Adjust update factor based on ratio\n        ratio = r_norm / max(s_norm, eps)\n        factor = 1.0 + t * min(ratio / mu, 2.0)\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        ratio = s_norm / max(r_norm, eps)\n        factor = 1.0 + t * min(ratio / mu, 2.0)\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: capture information about the update\n    # Use the maximum residual ratio if update occurred, otherwise 0\n    if mode != \"keep\":\n        aux = max(r_norm / max(s_norm, eps), s_norm / max(r_norm, eps))\n    else:\n        aux = 0.0\n\n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 3 (Score: 0.0768, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence with faster initial decay.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    # Add a small constant to denominator to prevent division by zero\n    # This gives faster decay initially\n    return c / ((k + 1.0 + 0.1 * np.sqrt(k + 1.0)) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with dynamic threshold.\n\n    The threshold adapts over iterations to be more responsive early on.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n    \n    # Dynamic threshold that diminishes with iterations\n    # This makes the algorithm more sensitive early, and more stable later\n    dynamic_mu = mu * (1.0 + 2.0/(k + 1.0))\n    \n    # Direction logic with dynamic threshold\n    if r_norm > dynamic_mu * max(s_norm, eps):\n        # More aggressive update when residuals are very imbalanced\n        # Use a larger step when the ratio is high\n        ratio = r_norm / max(s_norm, eps)\n        # Scale step size by log(ratio) but clip to avoid extreme values\n        scale = min(max(np.log(ratio), 0.1), 2.0)\n        new_rho = rho * (1.0 + t * scale)\n        mode = \"mul\"\n\n    elif s_norm > dynamic_mu * max(r_norm, eps):\n        ratio = s_norm / max(r_norm, eps)\n        scale = min(max(np.log(ratio), 0.1), 2.0)\n        new_rho = rho / (1.0 + t * scale)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n# Current Program\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    # Compute imbalance ratio\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Adjust step size based on ratio, but keep it bounded\n    # Use a moderate scaling: min(ratio / mu, 1.5) to prevent excessive updates\n    scale = min(ratio / mu, 1.5)\n    adjusted_t = t * (1.0 + 0.5 * scale)  # Increase t by up to 50% when ratio is large\n    \n    if r_norm > mu * max(s_norm, eps):\n        # Use adjusted step size for update\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: include information about adjustment\n    aux = adjusted_t\n\n    return new_rho, aux, mode\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Looking at the current program, it has a fitness score of 0.0828, which is the highest among the programs shown. However, there's room for improvement. The current approach uses an adjusted step size based on the residual ratio, which seems to work well. But we can try to refine it further.\n\nObservations:\n1. The current program uses `adjusted_t = t * (1.0 + 0.5 * scale)` where `scale = min(ratio / mu, 1.5)`. This increases the step size by up to 50% when the ratio is large.\n2. However, the adjustment might be too aggressive or not aggressive enough in certain scenarios.\n3. The auxiliary scalar `aux` is set to `adjusted_t`, which depends on residuals, potentially affecting C1 safety? But the problem statement says aux can be anything.\n\nLet's look at the best performing program (Program 1) which is actually the current program. To improve, we can try to make the update more adaptive while maintaining simplicity.\n\nIdeas for improvement:\n1. Use a dynamic threshold like in other programs, but with a more conservative approach.\n2. Adjust the step size scaling based on the iteration number to be more aggressive early and more stable later.\n3. Ensure the code remains simple (under 500 characters).\n\nLet's modify the `update_rho` function to incorporate a dynamic threshold that decreases with iterations, and adjust the step size scaling accordingly.\n\nHere are the changes:\n\n<<<<<<< SEARCH\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    # Compute imbalance ratio\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Adjust step size based on ratio, but keep it bounded\n    # Use a moderate scaling: min(ratio / mu, 1.5) to prevent excessive updates\n    scale = min(ratio / mu, 1.5)\n    adjusted_t = t * (1.0 + 0.5 * scale)  # Increase t by up to 50% when ratio is large\n    \n    if r_norm > mu * max(s_norm, eps):\n        # Use adjusted step size for update\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: include information about adjustment\n    aux = adjusted_t\n\n    return new_rho, aux, mode\n=======\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with dynamic threshold.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n    \n    # Dynamic threshold: more sensitive early, more stable later\n    # As k increases, dynamic_mu decreases towards mu\n    dynamic_mu = mu * (1.0 + 2.0 / (k + 2.0))\n    \n    # Compute imbalance ratio\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Adjust step size: more aggressive when ratio is large, but bounded\n    # Also, reduce adjustment as iterations progress\n    scale = min(ratio / dynamic_mu, 2.0)\n    # Weight for adjustment decreases with k\n    weight = 1.0 / (1.0 + 0.1 * k)\n    adjusted_t = t * (1.0 + weight * scale)\n    \n    if r_norm > dynamic_mu * max(s_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_norm > dynamic_mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Auxiliary scalar: track the dynamic threshold\n    aux = dynamic_mu\n    \n    return new_rho, aux, mode\n>>>>>>> REPLACE\n\nExplanation:\n1. Introduced a dynamic threshold `dynamic_mu` that starts higher (more sensitive to imbalances) and decreases towards `mu` as iterations increase. This helps to be more responsive early and stable later.\n2. Adjusted the step size scaling to use `dynamic_mu` instead of `mu` for consistency.\n3. Added a weight that decreases with `k` to reduce the adjustment magnitude over time, preventing overly aggressive updates in later iterations.\n4. Changed the auxiliary scalar to `dynamic_mu` to provide information about the current threshold, which might be useful for monitoring.\n5. Kept the overall structure similar to maintain simplicity.\n\nThis approach combines ideas from the top programs (dynamic threshold) with the current program's adjustment mechanism, potentially leading to better convergence and fitness.\n\nLet's also consider updating the `tau` function to have faster initial decay, which might help:\n\n<<<<<<< SEARCH\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n=======\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence with faster initial decay.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    # Add a term to accelerate initial decay\n    return c / ((k + 1.0 + 0.1 * np.sqrt(k + 1.0)) ** p)\n>>>>>>> REPLACE\n\nThis change makes the step size decay faster initially, which can help in early iterations to make larger adjustments when needed, and then become more stable later. This is inspired by Program 2 and 3.\n\nThese changes aim to improve the fitness score by making the algorithm more adaptive and responsive, especially in early iterations, while maintaining stability in later iterations. The code remains within reasonable length and complexity."]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}