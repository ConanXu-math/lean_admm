{"id": "4fc23bbb-1a79-4076-bddc-ff43ce6f1685", "code": "# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with adaptive step scaling.\n    Similar to top performers but with a slight variation in scaling.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n    \n    # Compute imbalance ratio for adaptive scaling\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Bounded linear scaling with a different bound for diversity\n    # Use min(ratio/mu, 1.5) instead of 1.4\n    scale = min(ratio / mu, 1.5)\n    # Adjust t with a different multiplier: 0.5 instead of 0.4\n    adjusted_t = t * (1.0 + 0.5 * scale)  # Increase t by up to 75% when ratio is large\n    \n    # Direction logic with fixed threshold (no dynamic_mu)\n    if r_norm > mu * max(s_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: include information about adjustment\n    aux = adjusted_t\n\n    return new_rho, aux, mode\n", "language": "python", "parent_id": "447a7fd7-7f71-495d-aaef-cf0c68ddc5d4", "generation": 2, "timestamp": 1770113018.418349, "iteration_found": 47, "metrics": {"combined_score": 0.08282272821092926, "metrics": {"converged": true, "iters": 12, "combined_score": 0.08282272821092926}, "artifacts": {"status": "CONVERGED", "iterations": 12, "eval_time": "24.700s"}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 11 lines with 10 lines\nChange 2: Replace 49 lines with 48 lines", "parent_metrics": {"combined_score": 0.07668660582378559, "metrics": {"converged": true, "iters": 13, "combined_score": 0.07668660582378559}, "artifacts": {"status": "CONVERGED", "iterations": 13, "eval_time": "29.145s"}}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert software developer tasked with iteratively improving a codebase.\nYour goal is to maximize the FITNESS SCORE while exploring diverse solutions across feature dimensions.\nThe system maintains a collection of diverse programs - both high fitness AND diversity are valuable.", "user": "# Current Program Information\n- Fitness: 0.0767\n- Feature coordinates: \n- Focus areas: - Fitness declined: 0.0829 \u2192 0.0767. Consider revising recent changes.\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 12 lines with 10 lines\nChange 2: Replace 29 lines with 30 lines\n- Metrics: combined_score: 0.0829, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08291186031768016}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '26.707s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 2\n- Changes: Change 1: Replace 12 lines with 10 lines\nChange 2: Replace 22 lines with 20 lines\nChange 3: Replace 8 lines with 8 lines\n- Metrics: combined_score: 0.0829, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08291186031768016}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '34.277s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 1\n- Changes: Change 1: Replace 6 lines with 4 lines\nChange 2: Replace 12 lines with 10 lines\nChange 3: Replace 5 lines with 5 lines\n- Metrics: combined_score: 0.0829, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08291186031768016}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '23.591s'}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design with adaptive step scaling based on residual imbalance.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Compute imbalance ratio for adaptive scaling\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Bounded linear scaling similar to top performers but with slight variation\n    # Use min(ratio/mu, 1.4) to prevent excessive updates\n    scale = min(ratio / mu, 1.4)\n    adjusted_t = t * (1.0 + 0.4 * scale)  # Increase t by up to 56% when ratio is large\n    \n    # Direction logic with fixed threshold\n    if r_norm > mu * max(s_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: include information about adjustment\n    aux = adjusted_t\n\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0829), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08291186031768016}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '23.591s'})\n\n### Program 2 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with moderate adjustment.\n    \"\"\"\n    # Summable step size\n    t = tau(k, c, p)\n    \n    # Compute imbalance ratio (always >= 1)\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Adjust step size based on ratio, but keep it bounded\n    # Use a moderate scaling: min(ratio / mu, 1.4) to prevent excessive updates\n    scale = min(ratio / mu, 1.4)\n    adjusted_t = t * (1.0 + 0.4 * scale)  # Increase t by up to 56% when ratio is large\n    \n    if r_norm > mu * max(s_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: include information about adjustment (C1-safe as it's based on t)\n    aux = adjusted_t\n\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0829), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08291186031768016}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '34.277s'})\n\n### Program 3 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with dynamic threshold.\n\n    The threshold adapts over iterations to be more responsive early on.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Compute imbalance ratio (always >= 1)\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Adjust step size based on ratio, but keep it bounded\n    # Use a moderate scaling: min(ratio / mu, 1.4) to prevent excessive updates\n    scale = min(ratio / mu, 1.4)\n    adjusted_t = t * (1.0 + 0.4 * scale)  # Increase t by up to 56% when ratio is large\n    \n    if r_norm > mu * max(s_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: include information about adjustment (C1-safe as it's based on t)\n    aux = adjusted_t\n\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0829), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08291186031768016}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '26.707s'})\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    # Compute imbalance ratio (always >= 1)\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Adjust step size based on ratio, but keep it bounded\n    # Use a moderate scaling: min(ratio / mu, 1.4) to prevent excessive updates\n    scale = min(ratio / mu, 1.4)\n    adjusted_t = t * (1.0 + 0.4 * scale)  # Increase t by up to 56% when ratio is large\n    \n    if r_norm > mu * max(s_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: include information about adjustment (C1-safe as it's based on t)\n    aux = adjusted_t\n\n    return new_rho, aux, mode\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n### Program D2 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with balanced step adjustment.\n\n    Conservative by design: adjusts step size based on residual imbalance.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    # Compute imbalance ratio (always >= 1)\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Adjust step size based on ratio, but keep it bounded\n    # Use a moderate scaling: min(ratio / mu, 1.4) to prevent excessive updates\n    scale = min(ratio / mu, 1.4)\n    adjusted_t = t * (1.0 + 0.4 * scale)  # Increase t by up to 56% when ratio is large\n    \n    if r_norm > mu * max(s_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: include information about adjustment (C1-safe as it's based on t)\n    aux = adjusted_t\n\n    return new_rho, aux, mode\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0829, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    # Compute imbalance ratio (always >= 1)\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Adjust step size based on ratio, but keep it bounded\n    # Use a moderate scaling: min(ratio / mu, 1.4) to prevent excessive updates\n    scale = min(ratio / mu, 1.4)\n    adjusted_t = t * (1.0 + 0.4 * scale)  # Increase t by up to 56% when ratio is large\n    \n    if r_norm > mu * max(s_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: include information about adjustment (C1-safe as it's based on t)\n    aux = adjusted_t\n\n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 2 (Score: 0.0829, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design with adaptive step scaling based on residual imbalance.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Compute imbalance ratio for adaptive scaling\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Bounded linear scaling similar to top performers but with slight variation\n    # Use min(ratio/mu, 1.4) to prevent excessive updates\n    scale = min(ratio / mu, 1.4)\n    adjusted_t = t * (1.0 + 0.4 * scale)  # Increase t by up to 56% when ratio is large\n    \n    # Direction logic with fixed threshold\n    if r_norm > mu * max(s_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: include information about adjustment\n    aux = adjusted_t\n\n    return new_rho, aux, mode\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], NumPy-based implementation, Comprehensive implementation\n\n### Inspiration 3 (Score: 0.0767, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence with faster initial decay.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    # Add a term to accelerate initial decay\n    return c / ((k + 1.0 + 0.1 * np.sqrt(k + 1.0)) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with dynamic threshold.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n    \n    # Dynamic threshold: more sensitive early, more stable later\n    # As k increases, dynamic_mu decreases towards mu\n    dynamic_mu = mu * (1.0 + 2.0 / (k + 2.0))\n    \n    # Compute imbalance ratio\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Adjust step size: more aggressive when ratio is large, but bounded\n    # Also, reduce adjustment as iterations progress\n    scale = min(ratio / dynamic_mu, 2.0)\n    # Weight for adjustment decreases with k\n    weight = 1.0 / (1.0 + 0.1 * k)\n    adjusted_t = t * (1.0 + weight * scale)\n    \n    if r_norm > dynamic_mu * max(s_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_norm > dynamic_mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Auxiliary scalar: track the dynamic threshold\n    aux = dynamic_mu\n    \n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n# Current Program\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence with faster initial decay.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    # Add a term to accelerate early decay, different from Inspiration 1\n    return c / ((k + 1.0 + 0.2 * (k + 1.0)**0.5) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with dynamic threshold\n    and adaptive step scaling.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n    \n    # Dynamic threshold that tightens with iterations\n    # This makes early iterations more responsive and later ones more stable\n    dynamic_mu = mu * (1.0 + 1.5 / (k + 1.0))\n    \n    # Compute residual ratios\n    if r_norm > eps and s_norm > eps:\n        ratio_r = r_norm / s_norm\n        ratio_s = s_norm / r_norm\n    else:\n        ratio_r = r_norm / max(s_norm, eps)\n        ratio_s = s_norm / max(r_norm, eps)\n    \n    # Direction logic with dynamic threshold and adaptive scaling\n    if r_norm > dynamic_mu * max(s_norm, eps):\n        # Scale step size by sqrt(ratio) for moderate adjustment\n        scale = min(max(np.sqrt(ratio_r), 0.5), 2.0)\n        new_rho = rho * (1.0 + t * scale)\n        mode = \"mul\"\n\n    elif s_norm > dynamic_mu * max(r_norm, eps):\n        scale = min(max(np.sqrt(ratio_s), 0.5), 2.0)\n        new_rho = rho / (1.0 + t * scale)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Looking at the current program, I notice a few issues that might be contributing to the fitness decline from 0.0829 to 0.0767:\n\n1. The `tau` function has been modified to include a term `0.2 * (k + 1.0)**0.5`, which makes it decay faster initially. However, this might violate the requirement that tau_k depends only on k and fixed constants? Actually, it's still valid since it's a fixed function of k. But it's different from the top performers which use a simpler formula.\n\n2. The update logic uses `np.sqrt(ratio_r)` and `np.sqrt(ratio_s)` which can be unstable and doesn't match the scaling approach in top performers. Top performers use a bounded linear scaling `min(ratio / mu, 1.4)` and adjust t by up to 56%.\n\n3. The dynamic threshold `dynamic_mu` changes with k, which might be too aggressive and cause instability compared to the fixed threshold in top performers.\n\n4. The auxiliary scalar `aux` is set to `t`, while top performers use `adjusted_t` which includes scaling information.\n\nSince top performers consistently achieve a score of 0.0829, I should align more closely with their approach while keeping some diversity. Let's simplify and adopt their scaling strategy while maintaining a slight variation for diversity.\n\nHere are the changes:\n\n<<<<<<< SEARCH\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence with faster initial decay.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    # Add a term to accelerate early decay, different from Inspiration 1\n    return c / ((k + 1.0 + 0.2 * (k + 1.0)**0.5) ** p)\n=======\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with dynamic threshold\n    and adaptive step scaling.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n    \n    # Dynamic threshold that tightens with iterations\n    # This makes early iterations more responsive and later ones more stable\n    dynamic_mu = mu * (1.0 + 1.5 / (k + 1.0))\n    \n    # Compute residual ratios\n    if r_norm > eps and s_norm > eps:\n        ratio_r = r_norm / s_norm\n        ratio_s = s_norm / r_norm\n    else:\n        ratio_r = r_norm / max(s_norm, eps)\n        ratio_s = s_norm / max(r_norm, eps)\n    \n    # Direction logic with dynamic threshold and adaptive scaling\n    if r_norm > dynamic_mu * max(s_norm, eps):\n        # Scale step size by sqrt(ratio) for moderate adjustment\n        scale = min(max(np.sqrt(ratio_r), 0.5), 2.0)\n        new_rho = rho * (1.0 + t * scale)\n        mode = \"mul\"\n\n    elif s_norm > dynamic_mu * max(r_norm, eps):\n        scale = min(max(np.sqrt(ratio_s), 0.5), 2.0)\n        new_rho = rho / (1.0 + t * scale)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n=======\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with adaptive step scaling.\n    Similar to top performers but with a slight variation in scaling.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n    \n    # Compute imbalance ratio for adaptive scaling\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Bounded linear scaling with a different bound for diversity\n    # Use min(ratio/mu, 1.5) instead of 1.4\n    scale = min(ratio / mu, 1.5)\n    # Adjust t with a different multiplier: 0.5 instead of 0.4\n    adjusted_t = t * (1.0 + 0.5 * scale)  # Increase t by up to 75% when ratio is large\n    \n    # Direction logic with fixed threshold (no dynamic_mu)\n    if r_norm > mu * max(s_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: include information about adjustment\n    aux = adjusted_t\n\n    return new_rho, aux, mode\n>>>>>>> REPLACE\n\nThese changes bring the program closer to the top performers while maintaining some diversity:\n1. Reverted `tau` to the standard form used by top performers for stability.\n2. Removed the dynamic threshold `dynamic_mu` in favor of fixed `mu` for consistency with high-scoring programs.\n3. Adopted the bounded linear scaling approach but with slightly different parameters (1.5 bound and 0.5 multiplier) to maintain diversity.\n4. Changed auxiliary scalar to `adjusted_t` which includes scaling information, matching the pattern in top performers.\n\nThis should improve fitness by aligning with proven strategies while keeping enough variation to explore the feature space."]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}