{"id": "afe8c77c-eae6-4426-a1ac-c5b4a7814da3", "code": "# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with balanced step adjustment.\n\n    Conservative by design: adjusts step size based on residual imbalance.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Compute imbalance ratio (always >= 1)\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Adjust step size based on ratio, but keep it bounded\n    # Use a different scaling than top performers for diversity: min(ratio / mu, 1.6)\n    scale = min(ratio / mu, 1.6)\n    # Increase t by up to 64% when ratio is large (0.4 * 1.6 = 0.64)\n    adjusted_t = t * (1.0 + 0.4 * scale)\n    \n    # Direction logic with fixed threshold\n    if r_norm > mu * max(s_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: include information about adjustment (C1-safe as it's based on t)\n    aux = adjusted_t\n\n    return new_rho, aux, mode\n", "language": "python", "parent_id": "130e826a-3321-4cb8-9501-c51427f5f47e", "generation": 3, "timestamp": 1770112996.314528, "iteration_found": 45, "metrics": {"combined_score": 0.08290430354693824, "metrics": {"converged": true, "iters": 12, "combined_score": 0.08290430354693824}, "artifacts": {"status": "CONVERGED", "iterations": 12, "eval_time": "36.496s"}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 12 lines with 10 lines\nChange 2: Replace 46 lines with 49 lines", "parent_metrics": {"combined_score": 0.07675777142078459, "metrics": {"converged": true, "iters": 13, "combined_score": 0.07675777142078459}, "artifacts": {"status": "CONVERGED", "iterations": 13, "eval_time": "29.074s"}}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert software developer tasked with iteratively improving a codebase.\nYour goal is to maximize the FITNESS SCORE while exploring diverse solutions across feature dimensions.\nThe system maintains a collection of diverse programs - both high fitness AND diversity are valuable.", "user": "# Current Program Information\n- Fitness: 0.0768\n- Feature coordinates: \n- Focus areas: - Fitness declined: 0.0829 \u2192 0.0768. Consider revising recent changes.\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 21 lines with 28 lines\nChange 2: Replace 15 lines with 15 lines\n- Metrics: combined_score: 0.0829, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08291186031768016}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '28.146s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 2\n- Changes: Change 1: Replace 12 lines with 10 lines\nChange 2: Replace 29 lines with 30 lines\n- Metrics: combined_score: 0.0829, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08291186031768016}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '26.707s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 1\n- Changes: Change 1: Replace 6 lines with 4 lines\nChange 2: Replace 12 lines with 10 lines\nChange 3: Replace 5 lines with 5 lines\n- Metrics: combined_score: 0.0829, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08291186031768016}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '23.591s'}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design with adaptive step scaling based on residual imbalance.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Compute imbalance ratio for adaptive scaling\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Bounded linear scaling similar to top performers but with slight variation\n    # Use min(ratio/mu, 1.4) to prevent excessive updates\n    scale = min(ratio / mu, 1.4)\n    adjusted_t = t * (1.0 + 0.4 * scale)  # Increase t by up to 56% when ratio is large\n    \n    # Direction logic with fixed threshold\n    if r_norm > mu * max(s_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: include information about adjustment\n    aux = adjusted_t\n\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0829), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08291186031768016}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '23.591s'})\n\n### Program 2 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with dynamic threshold.\n\n    The threshold adapts over iterations to be more responsive early on.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Compute imbalance ratio (always >= 1)\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Adjust step size based on ratio, but keep it bounded\n    # Use a moderate scaling: min(ratio / mu, 1.4) to prevent excessive updates\n    scale = min(ratio / mu, 1.4)\n    adjusted_t = t * (1.0 + 0.4 * scale)  # Increase t by up to 56% when ratio is large\n    \n    if r_norm > mu * max(s_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: include information about adjustment (C1-safe as it's based on t)\n    aux = adjusted_t\n\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0829), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08291186031768016}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '26.707s'})\n\n### Program 3 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with balanced step adjustment.\n\n    Conservative by design: adjusts step size based on residual imbalance.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    # Compute imbalance ratio (always >= 1)\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Adjust step size based on ratio, but keep it bounded\n    # Use a moderate scaling: min(ratio / mu, 1.4) to prevent excessive updates\n    scale = min(ratio / mu, 1.4)\n    adjusted_t = t * (1.0 + 0.4 * scale)  # Increase t by up to 56% when ratio is large\n    \n    if r_norm > mu * max(s_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: include information about adjustment (C1-safe as it's based on t)\n    aux = adjusted_t\n\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0829), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08291186031768016}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '28.146s'})\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0828)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    # Compute imbalance ratio\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Adjust step size based on ratio, but keep it bounded\n    # Use a moderate scaling: min(ratio / mu, 1.5) to prevent excessive updates\n    scale = min(ratio / mu, 1.5)\n    adjusted_t = t * (1.0 + 0.5 * scale)  # Increase t by up to 50% when ratio is large\n    \n    if r_norm > mu * max(s_norm, eps):\n        # Use adjusted step size for update\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: include information about adjustment\n    aux = adjusted_t\n\n    return new_rho, aux, mode\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n### Program D2 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    # Compute imbalance ratio (always >= 1)\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Adjust step size based on ratio, but keep it bounded\n    # Use a moderate scaling: min(ratio / mu, 1.4) to prevent excessive updates\n    scale = min(ratio / mu, 1.4)\n    adjusted_t = t * (1.0 + 0.4 * scale)  # Increase t by up to 56% when ratio is large\n    \n    if r_norm > mu * max(s_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: include information about adjustment (C1-safe as it's based on t)\n    aux = adjusted_t\n\n    return new_rho, aux, mode\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0829, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    # Compute imbalance ratio (always >= 1)\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Adjust step size based on ratio, but keep it bounded\n    # Use a moderate scaling: min(ratio / mu, 1.4) to prevent excessive updates\n    scale = min(ratio / mu, 1.4)\n    adjusted_t = t * (1.0 + 0.4 * scale)  # Increase t by up to 56% when ratio is large\n    \n    if r_norm > mu * max(s_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: include information about adjustment (C1-safe as it's based on t)\n    aux = adjusted_t\n\n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 2 (Score: 0.0829, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design with adaptive step scaling based on residual imbalance.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Compute imbalance ratio for adaptive scaling\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Bounded linear scaling similar to top performers but with slight variation\n    # Use min(ratio/mu, 1.4) to prevent excessive updates\n    scale = min(ratio / mu, 1.4)\n    adjusted_t = t * (1.0 + 0.4 * scale)  # Increase t by up to 56% when ratio is large\n    \n    # Direction logic with fixed threshold\n    if r_norm > mu * max(s_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: include information about adjustment\n    aux = adjusted_t\n\n    return new_rho, aux, mode\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], NumPy-based implementation, Comprehensive implementation\n\n### Inspiration 3 (Score: 0.0768, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence with faster initial decay.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    # Add a small constant to denominator to prevent division by zero\n    # This gives faster decay initially\n    return c / ((k + 1.0 + 0.1 * np.sqrt(k + 1.0)) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=2.5,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with dynamic threshold.\n\n    The threshold adapts over iterations to be more responsive early on.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n    \n    # Dynamic threshold that diminishes with iterations\n    # This makes the algorithm more sensitive early, and more stable later\n    dynamic_mu = mu * (1.0 + 2.0/(k + 1.0))\n    \n    # Direction logic with dynamic threshold\n    if r_norm > dynamic_mu * max(s_norm, eps):\n        # More aggressive update when residuals are very imbalanced\n        # Use a larger step when the ratio is high\n        ratio = r_norm / max(s_norm, eps)\n        # Scale step size by log(ratio) but clip to avoid extreme values\n        scale = min(max(np.log(ratio), 0.1), 2.0)\n        new_rho = rho * (1.0 + t * scale)\n        mode = \"mul\"\n\n    elif s_norm > dynamic_mu * max(r_norm, eps):\n        ratio = s_norm / max(r_norm, eps)\n        scale = min(max(np.log(ratio), 0.1), 2.0)\n        new_rho = rho / (1.0 + t * scale)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n# Current Program\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence with faster initial decay.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    # Add a small constant to denominator to prevent division by zero\n    # This gives faster decay initially\n    return c / ((k + 1.0 + 0.1 * np.sqrt(k + 1.0)) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with dynamic threshold.\n\n    The threshold adapts over iterations to be more responsive early on.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n    \n    # Dynamic threshold that diminishes with iterations\n    # This makes the algorithm more sensitive early, and more stable later\n    dynamic_mu = mu * (1.0 + 2.0/(k + 1.0))\n    \n    # Direction logic with dynamic threshold\n    if r_norm > dynamic_mu * max(s_norm, eps):\n        # More aggressive update when residuals are very imbalanced\n        # Use a larger step when the ratio is high\n        ratio = r_norm / max(s_norm, eps)\n        # Scale step size by log(ratio) but clip to avoid extreme values\n        scale = min(max(np.log(ratio), 0.1), 2.0)\n        new_rho = rho * (1.0 + t * scale)\n        mode = \"mul\"\n\n    elif s_norm > dynamic_mu * max(r_norm, eps):\n        ratio = s_norm / max(r_norm, eps)\n        scale = min(max(np.log(ratio), 0.1), 2.0)\n        new_rho = rho / (1.0 + t * scale)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Looking at the current program, I notice that its fitness score (0.0768) is lower than the top performers (0.0829). The main differences seem to be:\n\n1. The `tau` function has been modified to include a sqrt term, which might not be summable in the required sense (p > 1, but the denominator is more complex).\n2. The update rule uses a dynamic threshold `dynamic_mu` which changes with iteration, and the update factor uses `t * scale` where `scale` is based on log(ratio), which may be too aggressive or not C1-safe.\n3. The auxiliary scalar `aux` is set to `t` instead of an adjusted step size.\n\nThe top performers use a simpler approach:\n- A standard `tau` function: `c / ((k + 1.0) ** p)`\n- A fixed threshold `mu`\n- An adjusted step size `adjusted_t` that scales based on the ratio of residuals, but bounded\n- The update factor is `1.0 + adjusted_t` (or its reciprocal)\n- The auxiliary scalar is `adjusted_t`\n\nLet's simplify the current program to be more in line with the top performers while keeping some unique elements to maintain diversity. I'll focus on:\n\n1. Revert `tau` to the standard form to ensure it's summable and C1-safe.\n2. Use a fixed threshold `mu` but keep a unique scaling approach.\n3. Adjust the update factor to be `1.0 + adjusted_t` where `adjusted_t` is bounded and based on residual ratio.\n4. Ensure `aux` is set to `adjusted_t`.\n\nHowever, to maintain some diversity, I'll use a slightly different scaling factor than the top performers.\n\nHere are the changes:\n\n<<<<<<< SEARCH\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence with faster initial decay.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    # Add a small constant to denominator to prevent division by zero\n    # This gives faster decay initially\n    return c / ((k + 1.0 + 0.1 * np.sqrt(k + 1.0)) ** p)\n=======\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with dynamic threshold.\n\n    The threshold adapts over iterations to be more responsive early on.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n    \n    # Dynamic threshold that diminishes with iterations\n    # This makes the algorithm more sensitive early, and more stable later\n    dynamic_mu = mu * (1.0 + 2.0/(k + 1.0))\n    \n    # Direction logic with dynamic threshold\n    if r_norm > dynamic_mu * max(s_norm, eps):\n        # More aggressive update when residuals are very imbalanced\n        # Use a larger step when the ratio is high\n        ratio = r_norm / max(s_norm, eps)\n        # Scale step size by log(ratio) but clip to avoid extreme values\n        scale = min(max(np.log(ratio), 0.1), 2.0)\n        new_rho = rho * (1.0 + t * scale)\n        mode = \"mul\"\n\n    elif s_norm > dynamic_mu * max(r_norm, eps):\n        ratio = s_norm / max(r_norm, eps)\n        scale = min(max(np.log(ratio), 0.1), 2.0)\n        new_rho = rho / (1.0 + t * scale)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n=======\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with balanced step adjustment.\n\n    Conservative by design: adjusts step size based on residual imbalance.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Compute imbalance ratio (always >= 1)\n    if r_norm > eps and s_norm > eps:\n        ratio = max(r_norm / s_norm, s_norm / r_norm)\n    else:\n        ratio = 1.0\n    \n    # Adjust step size based on ratio, but keep it bounded\n    # Use a different scaling than top performers for diversity: min(ratio / mu, 1.6)\n    scale = min(ratio / mu, 1.6)\n    # Increase t by up to 64% when ratio is large (0.4 * 1.6 = 0.64)\n    adjusted_t = t * (1.0 + 0.4 * scale)\n    \n    # Direction logic with fixed threshold\n    if r_norm > mu * max(s_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        factor = 1.0 + adjusted_t\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: include information about adjustment (C1-safe as it's based on t)\n    aux = adjusted_t\n\n    return new_rho, aux, mode\n>>>>>>> REPLACE\n\nThese changes should bring the program closer to the successful patterns observed in the top performers while maintaining some diversity through slightly different scaling parameters (using 1.6 instead of 1.4 for the upper bound on scale). This should improve the fitness score while keeping the code within the required constraints (C1-safe, summable step size, etc.)."]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}