{"id": "27cf7e77-eb4d-402b-b14c-7b8e895f59ef", "code": "# initial_program.py\n# This file is evolved by AlphaEvolve\n# ONLY update_rho (and helpers) may be modified\n\nimport numpy as np\n\n\ndef tau(k, c=0.2, p=2.0, K0=5):\n    \"\"\"\n    C1-safe diminishing step size.\n    \"\"\"\n    if k < K0:\n        return 0.0\n    return c / ((k - K0 + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=2.0,\n    c=0.2,\n    p=2.0,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM update with balanced adjustments.\n    \"\"\"\n    t = tau(k, c=c, p=p)\n\n    # Trigger update when one residual dominates the other by factor mu\n    if r_norm > mu * max(s_norm, eps):\n        return rho * (1.0 + t), t, \"mul\"\n    elif s_norm > mu * max(r_norm, eps):\n        return rho / (1.0 + t), t, \"div\"\n    else:\n        # When residuals are balanced, make small adjustments based on their magnitude\n        avg_residual = (r_norm + s_norm) / 2.0\n        if avg_residual > 1.0:  # Large residuals\n            return rho * (1.0 + t/2), t, \"inc\"\n        elif avg_residual < 0.1:  # Small residuals\n            return rho / (1.0 + t/2), t, \"dec\"\n        else:\n            return rho, t, \"keep\"\n", "language": "python", "parent_id": "467d0974-a10e-415e-9e92-f9c0a6cbdc98", "generation": 2, "timestamp": 1770109228.030304, "iteration_found": 13, "metrics": {"combined_score": 0.07645586372571948, "metrics": {"converged": true, "iters": 13, "combined_score": 0.07645586372571948}, "artifacts": {"status": "CONVERGED", "iterations": 13, "eval_time": "25.553s"}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 8 lines with 7 lines\nChange 2: Replace 38 lines with 29 lines", "parent_metrics": {"combined_score": 0.07525245001302518, "metrics": {"converged": true, "iters": 13, "combined_score": 0.07525245001302518}, "artifacts": {"status": "CONVERGED", "iterations": 13, "eval_time": "32.521s"}}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert software developer tasked with iteratively improving a codebase.\nYour goal is to maximize the FITNESS SCORE while exploring diverse solutions across feature dimensions.\nThe system maintains a collection of diverse programs - both high fitness AND diversity are valuable.", "user": "# Current Program Information\n- Fitness: 0.0753\n- Feature coordinates: \n- Focus areas: - Fitness unchanged at 0.0753\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 7 lines with 8 lines\nChange 2: Replace 15 lines with 19 lines\nChange 3: Replace 3 lines with 3 lines\n- Metrics: combined_score: 0.0753, metrics: {'converged': True, 'iters': 13, 'combined_score': 0.07525245001302518}, artifacts: {'status': 'CONVERGED', 'iterations': 13, 'eval_time': '32.521s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 2\n- Changes: Change 1: Replace 34 lines with 24 lines\nChange 2: Replace 7 lines with 7 lines\n- Metrics: combined_score: 0.0757, metrics: {'converged': True, 'iters': 13, 'combined_score': 0.07568047337278107}, artifacts: {'status': 'CONVERGED', 'iterations': 13, 'eval_time': '30.613s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 1\n- Changes: Change 1: Replace 7 lines with 7 lines\nChange 2: Replace 34 lines with 30 lines\n- Metrics: combined_score: 0.0765, metrics: {'converged': True, 'iters': 13, 'combined_score': 0.07645586372571948}, artifacts: {'status': 'CONVERGED', 'iterations': 13, 'eval_time': '38.952s'}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.0765)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# ONLY update_rho (and helpers) may be modified\n\nimport numpy as np\n\n\ndef tau(k, c=0.2, p=2.0, K0=5):\n    \"\"\"\n    C1-safe diminishing step size.\n    \"\"\"\n    if k < K0:\n        return 0.0\n    return c / ((k - K0 + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=2.0,\n    c=0.2,\n    p=2.0,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM update with earlier and more frequent adjustments.\n    \"\"\"\n    t = tau(k, c=c, p=p)\n\n    # Less conservative trigger to respond more quickly to imbalances\n    if r_norm > mu * max(s_norm, eps):\n        return rho * (1.0 + t), t, \"mul\"\n    elif s_norm > mu * max(r_norm, eps):\n        return rho / (1.0 + t), t, \"div\"\n    else:\n        # When residuals are balanced, make small adjustments to encourage convergence\n        # If both residuals are large, increase rho; if both are small, decrease rho\n        avg_residual = (r_norm + s_norm) / 2.0\n        if avg_residual > 1.0:  # Large residuals\n            return rho * (1.0 + t/2), t, \"inc\"\n        elif avg_residual < 0.1:  # Small residuals\n            return rho / (1.0 + t/2), t, \"dec\"\n        else:\n            return rho, t, \"keep\"\n\n```\nKey features: Performs well on combined_score (0.0765), Performs well on metrics ({'converged': True, 'iters': 13, 'combined_score': 0.07645586372571948}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 13, 'eval_time': '38.952s'})\n\n### Program 2 (Score: 0.0757)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# ONLY update_rho (and helpers) may be modified\n\nimport numpy as np\n\n\ndef tau(k, c=0.3, p=1.8, K0=5):  # Adjusted defaults to match new parameters\n    \"\"\"\n    C1-safe diminishing step size with earlier start.\n    \"\"\"\n    if k < K0:\n        return 0.0\n    return c / ((k - K0 + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=2.0,  # Reduced from 3.0 to trigger updates more often\n    c=0.3,   # Increased from 0.2 for larger step adjustments\n    p=1.8,   # Reduced from 2.0 to make step size diminish slower\n    eps=1e-12,\n):\n    \"\"\"\n    Balanced ADMM update: more responsive than extremely conservative version.\n    Updates triggered when residuals are imbalanced by factor mu.\n    \"\"\"\n    t = tau(k, c=c, p=p)\n\n    # Trigger update when one residual dominates the other by factor mu\n    # Removed absolute condition since it's always true in practice\n    if r_norm > mu * max(s_norm, eps):\n        return rho * (1.0 + t), t, \"mul\"\n    if s_norm > mu * max(r_norm, eps):\n        return rho / (1.0 + t), t, \"div\"\n\n    return rho, t, \"keep\"\n\n```\nKey features: Performs well on combined_score (0.0757), Performs well on metrics ({'converged': True, 'iters': 13, 'combined_score': 0.07568047337278107}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 13, 'eval_time': '30.613s'})\n\n### Program 3 (Score: 0.0753)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# ONLY update_rho (and helpers) may be modified\n\nimport numpy as np\n\n\ndef tau(k, c=0.2, p=1.0, K0=5):\n    \"\"\"\n    C1-safe diminishing step size.\n    \"\"\"\n    if k < K0:\n        # Allow small updates even early on\n        return c / ((K0 + 1.0) ** p)\n    return c / ((k - K0 + 2.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=2.0,\n    c=0.3,\n    p=1.0,\n    eps=1e-12,\n):\n    \"\"\"\n    Intentionally conservative C1-safe ADMM update.\n\n    Slower than standard because updates are triggered\n    only under *extreme* residual imbalance.\n    \"\"\"\n\n    t = tau(k, c=c, p=p)\n\n    # Less conservative trigger: use ratio-based adjustment\n    ratio = r_norm / max(s_norm, eps)\n    # Adjust mu to be dynamic based on iteration\n    effective_mu = mu * (1.0 + 1.0 / (k + 1.0))\n    \n    if ratio > effective_mu:\n        # Increase rho when primal residual is larger\n        return rho * (1.0 + t), t, \"mul\"\n    elif 1.0 / ratio > effective_mu:\n        # Decrease rho when dual residual is larger\n        return rho / (1.0 + t), t, \"div\"\n    else:\n        # Small adjustment based on which residual is larger\n        if r_norm > s_norm:\n            return rho * (1.0 + 0.5 * t), t, \"small_mul\"\n        elif s_norm > r_norm:\n            return rho / (1.0 + 0.5 * t), t, \"small_div\"\n        else:\n            return rho, t, \"keep\"\n\n```\nKey features: Performs well on combined_score (0.0753), Performs well on metrics ({'converged': True, 'iters': 13, 'combined_score': 0.07525245001302518}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 13, 'eval_time': '32.521s'})\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0691)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# ONLY update_rho (and helpers) may be modified\n\nimport numpy as np\n\n\ndef tau(k, c=0.2, p=2.0, K0=10):\n    \"\"\"\n    C1-safe diminishing step size.\n    \"\"\"\n    if k < K0:\n        return 0.0\n    return c / ((k - K0 + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=2.0,  # Reduced from 3.0 to be more responsive\n    c=0.2,\n    p=2.0,\n    eps=1e-12,\n):\n    \"\"\"\n    Balanced ADMM update: more responsive than before but still stable.\n    Updates are triggered when one residual significantly dominates the other.\n    \"\"\"\n    t = tau(k, c=c, p=p)\n\n    # More sensitive trigger: only require relative dominance\n    # But add a small absolute threshold to avoid updates when both are tiny\n    if r_norm > mu * max(s_norm, eps) and r_norm > 1e-8:\n        return rho * (1.0 + t), t, \"mul\"\n\n    if s_norm > mu * max(r_norm, eps) and s_norm > 1e-8:\n        return rho / (1.0 + t), t, \"div\"\n\n    # Additional condition: if both residuals are large, adjust rho to potentially speed up convergence\n    # This adds diversity to the approach\n    if max(r_norm, s_norm) > 1e-4 and abs(r_norm - s_norm) < 0.5 * min(r_norm, s_norm):\n        # If r_norm is slightly larger, increase rho, else decrease\n        if r_norm > s_norm:\n            return rho * (1.0 + 0.5 * t), t, \"bal_mul\"\n        else:\n            return rho / (1.0 + 0.5 * t), t, \"bal_div\"\n\n    # If neither condition is met, keep rho unchanged\n    return rho, t, \"keep\"\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n### Program D2 (Score: 0.0691)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# ONLY update_rho (and helpers) may be modified\n\nimport numpy as np\n\n\ndef tau(k, c=0.2, p=2.0, K0=10):\n    \"\"\"\n    C1-safe diminishing step size.\n    \"\"\"\n    if k < K0:\n        return 0.0\n    return c / ((k - K0 + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=0.2,\n    p=2.0,\n    eps=1e-12,\n):\n    \"\"\"\n    Intentionally conservative C1-safe ADMM update.\n\n    Slower than standard because updates are triggered\n    only under *extreme* residual imbalance.\n    \"\"\"\n\n    t = tau(k, c=c, p=p)\n\n    # Extremely conservative trigger:\n    # require both relative AND absolute dominance\n    if (\n        r_norm > mu * max(s_norm, eps)\n        and r_norm > (mu ** 2) * eps\n    ):\n        return rho * (1.0 + t), t, \"mul\"\n\n    if (\n        s_norm > mu * max(r_norm, eps)\n        and s_norm > (mu ** 2) * eps\n    ):\n        return rho / (1.0 + t), t, \"div\"\n\n    return rho, t, \"keep\"\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0765, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# ONLY update_rho (and helpers) may be modified\n\nimport numpy as np\n\n\ndef tau(k, c=0.2, p=2.0, K0=5):\n    \"\"\"\n    C1-safe diminishing step size.\n    \"\"\"\n    if k < K0:\n        return 0.0\n    return c / ((k - K0 + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=2.0,\n    c=0.2,\n    p=2.0,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM update with earlier and more frequent adjustments.\n    \"\"\"\n    t = tau(k, c=c, p=p)\n\n    # Less conservative trigger to respond more quickly to imbalances\n    if r_norm > mu * max(s_norm, eps):\n        return rho * (1.0 + t), t, \"mul\"\n    elif s_norm > mu * max(r_norm, eps):\n        return rho / (1.0 + t), t, \"div\"\n    else:\n        # When residuals are balanced, make small adjustments to encourage convergence\n        # If both residuals are large, increase rho; if both are small, decrease rho\n        avg_residual = (r_norm + s_norm) / 2.0\n        if avg_residual > 1.0:  # Large residuals\n            return rho * (1.0 + t/2), t, \"inc\"\n        elif avg_residual < 0.1:  # Small residuals\n            return rho / (1.0 + t/2), t, \"dec\"\n        else:\n            return rho, t, \"keep\"\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 2 (Score: 0.0691, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# ONLY update_rho (and helpers) may be modified\n\nimport numpy as np\n\n\ndef tau(k, c=0.2, p=2.0, K0=10):\n    \"\"\"\n    C1-safe diminishing step size.\n    \"\"\"\n    if k < K0:\n        return 0.0\n    return c / ((k - K0 + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=0.2,\n    p=2.0,\n    eps=1e-12,\n):\n    \"\"\"\n    Intentionally conservative C1-safe ADMM update.\n\n    Slower than standard because updates are triggered\n    only under *extreme* residual imbalance.\n    \"\"\"\n\n    t = tau(k, c=c, p=p)\n\n    # Extremely conservative trigger:\n    # require both relative AND absolute dominance\n    if (\n        r_norm > mu * max(s_norm, eps)\n        and r_norm > (mu ** 2) * eps\n    ):\n        return rho * (1.0 + t), t, \"mul\"\n\n    if (\n        s_norm > mu * max(r_norm, eps)\n        and s_norm > (mu ** 2) * eps\n    ):\n        return rho / (1.0 + t), t, \"div\"\n\n    return rho, t, \"keep\"\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], NumPy-based implementation, Comprehensive implementation\n\n### Inspiration 3 (Score: 0.0677, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# ONLY update_rho (and helpers) may be modified\n\nimport numpy as np\n\n\ndef tau(k, c=0.2, p=1.5, K0=5):\n    \"\"\"\n    C1-safe diminishing step size.\n    Start updates earlier with smaller steps.\n    \"\"\"\n    if k < K0:\n        # Small step size for early iterations\n        return c / ((k + 1.0) ** p) * 0.1\n    return c / ((k - K0 + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=0.2,\n    p=2.0,\n    eps=1e-12,\n):\n    \"\"\"\n    Intentionally conservative C1-safe ADMM update.\n\n    Slower than standard because updates are triggered\n    only under *extreme* residual imbalance.\n    \"\"\"\n\n    t = tau(k, c=c, p=p)\n\n    # Balanced trigger: use relative imbalance without absolute condition\n    # Adjust mu to be slightly smaller for more responsiveness\n    if r_norm > 2.0 * max(s_norm, eps):\n        return rho * (1.0 + t), t, \"mul\"\n\n    if s_norm > 2.0 * max(r_norm, eps):\n        return rho / (1.0 + t), t, \"div\"\n\n    return rho, t, \"keep\"\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n# Current Program\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# ONLY update_rho (and helpers) may be modified\n\nimport numpy as np\n\n\ndef tau(k, c=0.2, p=1.0, K0=5):\n    \"\"\"\n    C1-safe diminishing step size.\n    \"\"\"\n    if k < K0:\n        # Allow small updates even early on\n        return c / ((K0 + 1.0) ** p)\n    return c / ((k - K0 + 2.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=2.0,\n    c=0.3,\n    p=1.0,\n    eps=1e-12,\n):\n    \"\"\"\n    Intentionally conservative C1-safe ADMM update.\n\n    Slower than standard because updates are triggered\n    only under *extreme* residual imbalance.\n    \"\"\"\n\n    t = tau(k, c=c, p=p)\n\n    # Less conservative trigger: use ratio-based adjustment\n    ratio = r_norm / max(s_norm, eps)\n    # Adjust mu to be dynamic based on iteration\n    effective_mu = mu * (1.0 + 1.0 / (k + 1.0))\n    \n    if ratio > effective_mu:\n        # Increase rho when primal residual is larger\n        return rho * (1.0 + t), t, \"mul\"\n    elif 1.0 / ratio > effective_mu:\n        # Decrease rho when dual residual is larger\n        return rho / (1.0 + t), t, \"div\"\n    else:\n        # Small adjustment based on which residual is larger\n        if r_norm > s_norm:\n            return rho * (1.0 + 0.5 * t), t, \"small_mul\"\n        elif s_norm > r_norm:\n            return rho / (1.0 + 0.5 * t), t, \"small_div\"\n        else:\n            return rho, t, \"keep\"\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Looking at the current program and its history, I notice that the best performing program (Score: 0.0765) has a simpler approach with fewer conditions. The current program has a more complex update rule with dynamic mu and small adjustments, which might be causing it to be less effective. The fitness has been decreasing from 0.0765 to 0.0753, suggesting that the current approach may be overcomplicating things.\n\nKey observations:\n1. The top program uses a straightforward approach: if r_norm > mu*s_norm, multiply; if s_norm > mu*r_norm, divide; otherwise, make small adjustments based on average residual.\n2. The current program uses a dynamic effective_mu that changes with iteration, which might be too aggressive or not well-tuned.\n3. The current program also has a complex else clause with small adjustments, which might be making updates too frequent and destabilizing convergence.\n\nLet's simplify towards the approach of the top program while incorporating some of the better aspects:\n1. Use a fixed mu (2.0) as in the top program\n2. Remove the dynamic effective_mu\n3. Keep the balanced adjustment in the else clause, but make it simpler\n4. Adjust the tau function to be more standard\n\nHowever, note that the current program has p=1.0 which makes tau diminish slower than p=2.0. The top program uses p=2.0. Let's try a balanced approach.\n\nHere are the changes:\n\n<<<<<<< SEARCH\ndef tau(k, c=0.2, p=1.0, K0=5):\n    \"\"\"\n    C1-safe diminishing step size.\n    \"\"\"\n    if k < K0:\n        # Allow small updates even early on\n        return c / ((K0 + 1.0) ** p)\n    return c / ((k - K0 + 2.0) ** p)\n=======\ndef tau(k, c=0.2, p=2.0, K0=5):\n    \"\"\"\n    C1-safe diminishing step size.\n    \"\"\"\n    if k < K0:\n        return 0.0\n    return c / ((k - K0 + 1.0) ** p)\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=2.0,\n    c=0.3,\n    p=1.0,\n    eps=1e-12,\n):\n    \"\"\"\n    Intentionally conservative C1-safe ADMM update.\n\n    Slower than standard because updates are triggered\n    only under *extreme* residual imbalance.\n    \"\"\"\n\n    t = tau(k, c=c, p=p)\n\n    # Less conservative trigger: use ratio-based adjustment\n    ratio = r_norm / max(s_norm, eps)\n    # Adjust mu to be dynamic based on iteration\n    effective_mu = mu * (1.0 + 1.0 / (k + 1.0))\n    \n    if ratio > effective_mu:\n        # Increase rho when primal residual is larger\n        return rho * (1.0 + t), t, \"mul\"\n    elif 1.0 / ratio > effective_mu:\n        # Decrease rho when dual residual is larger\n        return rho / (1.0 + t), t, \"div\"\n    else:\n        # Small adjustment based on which residual is larger\n        if r_norm > s_norm:\n            return rho * (1.0 + 0.5 * t), t, \"small_mul\"\n        elif s_norm > r_norm:\n            return rho / (1.0 + 0.5 * t), t, \"small_div\"\n        else:\n            return rho, t, \"keep\"\n=======\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=2.0,\n    c=0.2,\n    p=2.0,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM update with balanced adjustments.\n    \"\"\"\n    t = tau(k, c=c, p=p)\n\n    # Trigger update when one residual dominates the other by factor mu\n    if r_norm > mu * max(s_norm, eps):\n        return rho * (1.0 + t), t, \"mul\"\n    elif s_norm > mu * max(r_norm, eps):\n        return rho / (1.0 + t), t, \"div\"\n    else:\n        # When residuals are balanced, make small adjustments based on their magnitude\n        avg_residual = (r_norm + s_norm) / 2.0\n        if avg_residual > 1.0:  # Large residuals\n            return rho * (1.0 + t/2), t, \"inc\"\n        elif avg_residual < 0.1:  # Small residuals\n            return rho / (1.0 + t/2), t, \"dec\"\n        else:\n            return rho, t, \"keep\"\n>>>>>>> REPLACE\n\nThese changes:\n1. Simplify tau to be standard: no updates before K0, and use standard formula\n2. Use p=2.0 which is more standard for diminishing step sizes\n3. Remove the dynamic effective_mu and use fixed mu=2.0\n4. Use the balanced adjustment from the top program in the else clause, which seems to work well\n5. Adjust c back to 0.2 to match the top program\n\nThis should make the program more similar to the best performing one while maintaining some diversity through the balanced adjustments in the else clause. The fitness should improve because the top program has shown the best performance (0.0765), and we're moving towards that approach while keeping the code length reasonable."]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}