{"id": "aa94c4d7-2264-4501-a1b4-2c7e12540b39", "code": "# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > mu * max(s_norm, eps):\n        new_rho = rho * (1.0 + t)\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        new_rho = rho / (1.0 + t)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n", "language": "python", "parent_id": "c1ec067c-4f35-460f-9aea-0dc6b05d622d", "generation": 2, "timestamp": 1770121300.773102, "iteration_found": 9, "metrics": {"combined_score": 0.07692307692307693, "metrics": {"converged": true, "iters": 13, "combined_score": 0.07692307692307693}, "artifacts": {"status": "CONVERGED", "iterations": 13, "eval_time": "20.457s"}, "formal_certification": "Lean4_Auto_Proven"}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 28 lines with 15 lines\nChange 2: Replace 28 lines with 19 lines", "parent_metrics": {"combined_score": 0.038461538461538464, "metrics": {"converged": true, "iters": 13, "combined_score": 0.038461538461538464}, "artifacts": {"status": "CONVERGED", "iterations": 13, "eval_time": "34.458s"}, "formal_certification": "Lean4_Not_Auto_Proven"}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert software developer tasked with iteratively improving a codebase.\nYour goal is to maximize the FITNESS SCORE while exploring diverse solutions across feature dimensions.\nThe system maintains a collection of diverse programs - both high fitness AND diversity are valuable.", "user": "# Current Program Information\n- Fitness: 0.0385\n- Feature coordinates: \n- Focus areas: - Fitness declined: 0.0769 \u2192 0.0385. Consider revising recent changes.\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 41 lines with 36 lines\n- Metrics: combined_score: 0.0769, metrics: {'converged': True, 'iters': 13, 'combined_score': 0.07692307692307693}, artifacts: {'status': 'CONVERGED', 'iterations': 13, 'eval_time': '20.184s'}, formal_certification: Lean4_Auto_Proven\n- Outcome: Improvement in all metrics\n\n### Attempt 2\n- Changes: Unknown changes\n- Metrics: combined_score: 0.0769, metrics: {'converged': True, 'iters': 13, 'combined_score': 0.07692307692307693}, artifacts: {'status': 'CONVERGED', 'iterations': 13, 'eval_time': '21.696s'}, formal_certification: Lean4_Auto_Proven\n- Outcome: Improvement in all metrics\n\n### Attempt 1\n- Changes: Change 1: Replace 12 lines with 23 lines\nChange 2: Replace 12 lines with 16 lines\nChange 3: Replace 36 lines with 40 lines\n- Metrics: combined_score: 0.0769, metrics: {'converged': True, 'iters': 13, 'combined_score': 0.07692307692307693}, artifacts: {'status': 'CONVERGED', 'iterations': 13, 'eval_time': '26.374s'}, formal_certification: Lean4_Auto_Proven\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.0769)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Adaptive threshold that tightens over time\n    # As k increases, t decreases, so mu_adj increases towards mu\n    mu_adj = mu * (1.0 + t)  # Start slightly larger and approach mu\n    \n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > mu_adj * max(s_norm, eps):\n        # More aggressive update when residuals are very imbalanced\n        # Scale the adjustment by the ratio, but bounded by t\n        ratio = r_norm / max(s_norm, eps)\n        # Ensure adjustment is at least t and at most 2*t\n        adj = min(2.0 * t, max(t, t * (ratio - mu_adj) / mu_adj))\n        new_rho = rho * (1.0 + adj)\n        mode = \"mul\"\n\n    elif s_norm > mu_adj * max(r_norm, eps):\n        ratio = s_norm / max(r_norm, eps)\n        adj = min(2.0 * t, max(t, t * (ratio - mu_adj) / mu_adj))\n        new_rho = rho / (1.0 + adj)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0769), Performs well on metrics ({'converged': True, 'iters': 13, 'combined_score': 0.07692307692307693}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 13, 'eval_time': '26.374s'}), Performs well on formal_certification (Lean4_Auto_Proven)\n\n### Program 2 (Score: 0.0769)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > mu * max(s_norm, eps):\n        new_rho = rho * (1.0 + t)\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        new_rho = rho / (1.0 + t)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0769), Performs well on metrics ({'converged': True, 'iters': 13, 'combined_score': 0.07692307692307693}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 13, 'eval_time': '21.696s'}), Performs well on formal_certification (Lean4_Auto_Proven)\n\n### Program 3 (Score: 0.0769)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > mu * max(s_norm, eps):\n        new_rho = rho * (1.0 + t)\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        new_rho = rho / (1.0 + t)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0769), Performs well on metrics ({'converged': True, 'iters': 13, 'combined_score': 0.07692307692307693}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 13, 'eval_time': '20.184s'}), Performs well on formal_certification (Lean4_Auto_Proven)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0385)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic with adaptive step scaling based on residual ratio\n    # Compute the ratio, handling small values\n    ratio = r_norm / max(s_norm, eps)\n    \n    if ratio > mu:\n        # Scale the step by how much the ratio exceeds mu, but cap it\n        scale = min(ratio / mu, 2.0)  # Cap at 2 to prevent too large steps\n        new_rho = rho * (1.0 + t * scale)\n        mode = \"mul\"\n    elif 1.0 / ratio > mu:\n        ratio_inv = s_norm / max(r_norm, eps)\n        scale = min(ratio_inv / mu, 2.0)\n        new_rho = rho / (1.0 + t * scale)\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n### Program D2 (Score: 0.0385)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Adjust mu to be more responsive while maintaining stability\n    mu_adj = 2.0\n    \n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > mu_adj * max(s_norm, eps):\n        # Make update more aggressive when ratio is very large\n        ratio = r_norm / max(s_norm, eps)\n        factor = 1.0 + t * min(ratio / mu_adj, 2.0)\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu_adj * max(r_norm, eps):\n        ratio = s_norm / max(r_norm, eps)\n        factor = 1.0 + t * min(ratio / mu_adj, 2.0)\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: track the actual change factor\n    if mode == \"mul\":\n        aux = new_rho / rho\n    elif mode == \"div\":\n        aux = rho / new_rho\n    else:\n        aux = 1.0\n\n    return new_rho, aux, mode\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0769, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > mu * max(s_norm, eps):\n        new_rho = rho * (1.0 + t)\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        new_rho = rho / (1.0 + t)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 2 (Score: 0.0769, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > mu * max(s_norm, eps):\n        new_rho = rho * (1.0 + t)\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        new_rho = rho / (1.0 + t)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], NumPy-based implementation, Comprehensive implementation\n\n### Inspiration 3 (Score: 0.0357, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design with dynamic threshold.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n    \n    # Adjust mu to be more aggressive early, conservative later\n    # As k increases, mu increases to reduce updates\n    # This helps in early exploration and later refinement\n    dynamic_mu = mu * (1.0 + 0.1 * np.log1p(k))\n    \n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > dynamic_mu * max(s_norm, eps):\n        # Use a larger step when residual ratio is very large\n        ratio = r_norm / max(s_norm, eps)\n        # Clip the scaling factor to be between 1 and 2\n        scale = min(2.0, max(1.0, 0.5 * ratio / dynamic_mu))\n        new_rho = rho * (1.0 + t * scale)\n        mode = \"mul\"\n    elif s_norm > dynamic_mu * max(r_norm, eps):\n        ratio = s_norm / max(r_norm, eps)\n        scale = min(2.0, max(1.0, 0.5 * ratio / dynamic_mu))\n        new_rho = rho / (1.0 + t * scale)\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n    \n    return new_rho, aux, mode\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], NumPy-based implementation, Comprehensive implementation\n\n# Current Program\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Adjust mu to be more responsive while maintaining stability\n    mu_adj = 2.0\n    \n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > mu_adj * max(s_norm, eps):\n        # Make update more aggressive when ratio is very large\n        ratio = r_norm / max(s_norm, eps)\n        factor = 1.0 + t * min(ratio / mu_adj, 2.0)\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu_adj * max(r_norm, eps):\n        ratio = s_norm / max(r_norm, eps)\n        factor = 1.0 + t * min(ratio / mu_adj, 2.0)\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: track the actual change factor\n    if mode == \"mul\":\n        aux = new_rho / rho\n    elif mode == \"div\":\n        aux = rho / new_rho\n    else:\n        aux = 1.0\n\n    return new_rho, aux, mode\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Looking at the current program, I notice its fitness score dropped from 0.0769 to 0.0385. The top-performing programs all have a score of 0.0769 and share a simpler structure: they use a fixed `mu=3.0` and adjust `rho` by exactly `(1 + t)` or `1/(1 + t)` without scaling by the residual ratio. The current program uses `mu_adj=2.0` and scales the step by `min(ratio / mu_adj, 2.0)`, which might be too aggressive and less stable.\n\nAdditionally, the auxiliary scalar `aux` in top programs is always `t` (the tau value), while the current program computes `aux` as the actual change factor, which depends on residuals. The requirement likely expects `aux` to be independent of residuals (as per the C1-safe condition). This could be causing the fitness drop.\n\nLet's revert to a simpler approach similar to the top performers, but with a slight twist to maintain diversity. We'll keep `mu=3.0` and use the basic update rule, but perhaps adjust the step size sequence slightly.\n\nHowever, note that the current program uses `mu_adj=2.0` which is different from the standard `mu=3.0`. This might be causing more frequent updates, which could be less stable. Let's change it back to `mu=3.0` and remove the scaling by ratio.\n\nAlso, the auxiliary scalar should be `t` (tau) as in the top programs.\n\nHere are the changes:\n\n1. Change `mu_adj` back to `mu` (use the parameter `mu` which defaults to 3.0).\n2. Remove the scaling by `min(ratio / mu_adj, 2.0)` and use just `t` for the adjustment.\n3. Change the auxiliary scalar to be `t` instead of the actual change factor.\n\nLet's implement these changes:\n\n<<<<<<< SEARCH\n    # Adjust mu to be more responsive while maintaining stability\n    mu_adj = 2.0\n    \n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > mu_adj * max(s_norm, eps):\n        # Make update more aggressive when ratio is very large\n        ratio = r_norm / max(s_norm, eps)\n        factor = 1.0 + t * min(ratio / mu_adj, 2.0)\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu_adj * max(r_norm, eps):\n        ratio = s_norm / max(r_norm, eps)\n        factor = 1.0 + t * min(ratio / mu_adj, 2.0)\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: track the actual change factor\n    if mode == \"mul\":\n        aux = new_rho / rho\n    elif mode == \"div\":\n        aux = rho / new_rho\n    else:\n        aux = 1.0\n=======\n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > mu * max(s_norm, eps):\n        new_rho = rho * (1.0 + t)\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        new_rho = rho / (1.0 + t)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n>>>>>>> REPLACE\n\nThis change makes the program very similar to the top performers, which should restore the high fitness score. However, to add some diversity, we can consider a small modification: instead of using `mu` directly, we can adjust it slightly with a time-dependent factor that converges to 1. But the top program 1 already does something similar with `mu_adj = mu * (1.0 + t)`. Let's adopt that approach to maintain some uniqueness while likely preserving performance.\n\nActually, looking at program 1, it uses `mu_adj = mu * (1.0 + t)` which starts slightly larger and approaches `mu`. This might help in early iterations. Let's incorporate that for diversity, but keep the update step simple (just `t` without scaling by ratio). This is different from program 1 which uses scaling by ratio in the adjustment.\n\nSo let's do:\n\n<<<<<<< SEARCH\n    # Adjust mu to be more responsive while maintaining stability\n    mu_adj = 2.0\n    \n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > mu_adj * max(s_norm, eps):\n        # Make update more aggressive when ratio is very large\n        ratio = r_norm / max(s_norm, eps)\n        factor = 1.0 + t * min(ratio / mu_adj, 2.0)\n        new_rho = rho * factor\n        mode = \"mul\"\n\n    elif s_norm > mu_adj * max(r_norm, eps):\n        ratio = s_norm / max(r_norm, eps)\n        factor = 1.0 + t * min(ratio / mu_adj, 2.0)\n        new_rho = rho / factor\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: track the actual change factor\n    if mode == \"mul\":\n        aux = new_rho / rho\n    elif mode == \"div\":\n        aux = rho / new_rho\n    else:\n        aux = 1.0\n=======\n    # Adaptive threshold that tightens over time\n    # As k increases, t decreases, so mu_adj decreases towards mu\n    mu_adj = mu * (1.0 + t)  # Start slightly larger and approach mu\n    \n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > mu_adj * max(s_norm, eps):\n        new_rho = rho * (1.0 + t)\n        mode = \"mul\"\n\n    elif s_norm > mu_adj * max(r_norm, eps):\n        new_rho = rho / (1.0 + t)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n>>>>>>> REPLACE\n\nThis approach is similar to program 1 but without the scaling by ratio in the adjustment factor. It maintains the simple update step while having an adaptive threshold. This should be both effective and diverse.\n\nLet's also ensure the docstring is consistent. No changes needed there.\n\nThese changes should improve the fitness score back to around 0.0769 while keeping the program distinct from the top performers."]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}