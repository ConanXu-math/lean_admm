{"id": "cf175fa1-b406-421a-9a67-cb5a49ad0445", "code": "# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design with adaptive threshold.\n    \"\"\"\n    # Adjust mu to become stricter as iterations increase\n    # This helps in finer convergence control\n    adjusted_mu = 1.0 + (mu - 1.0) / (k + 1.0)\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > adjusted_mu * max(s_norm, eps):\n        new_rho = rho * (1.0 + t)\n        mode = \"mul\"\n\n    elif s_norm > adjusted_mu * max(r_norm, eps):\n        new_rho = rho / (1.0 + t)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n", "language": "python", "parent_id": "d9a08482-6522-4051-a107-51fb32319421", "generation": 1, "timestamp": 1770450825.94511, "iteration_found": 7, "metrics": {"combined_score": 0.07692307692307693, "metrics": {"converged": true, "iters": 13, "combined_score": 0.07692307692307693}, "artifacts": {"status": "CONVERGED", "iterations": 13, "eval_time": "21.026s"}, "formal_certification": "Lean4_Auto_Proven"}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 36 lines with 39 lines", "parent_metrics": {"combined_score": 0.07692307692307693, "metrics": {"converged": true, "iters": 13, "combined_score": 0.07692307692307693}, "artifacts": {"status": "CONVERGED", "iterations": 13, "eval_time": "20.735s"}, "formal_certification": "Lean4_Auto_Proven"}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert software developer tasked with iteratively improving a codebase.\nYour goal is to maximize the FITNESS SCORE while exploring diverse solutions across feature dimensions.\nThe system maintains a collection of diverse programs - both high fitness AND diversity are valuable.", "user": "# Current Program Information\n- Fitness: 0.0769\n- Feature coordinates: \n- Focus areas: - Fitness improved: 0.0417 \u2192 0.0769\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 15 lines with 30 lines\nChange 2: Replace 10 lines with 12 lines\n- Metrics: combined_score: 0.0417, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.041666666666666664}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '24.987s'}, formal_certification: Lean4_Not_Auto_Proven\n- Outcome: Regression in all metrics\n\n### Attempt 2\n- Changes: Change 1: Replace 36 lines with 44 lines\nChange 2: Replace 3 lines with 4 lines\n- Metrics: combined_score: 0.0769, metrics: {'converged': True, 'iters': 13, 'combined_score': 0.07692307692307693}, artifacts: {'status': 'CONVERGED', 'iterations': 13, 'eval_time': '21.544s'}, formal_certification: Lean4_Auto_Proven\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Unknown changes\n- Metrics: combined_score: 0.0769, metrics: {'converged': True, 'iters': 13, 'combined_score': 0.07692307692307693}, artifacts: {'status': 'CONVERGED', 'iterations': 13, 'eval_time': '20.735s'}, formal_certification: Lean4_Auto_Proven\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.0769)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > mu * max(s_norm, eps):\n        new_rho = rho * (1.0 + t)\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        new_rho = rho / (1.0 + t)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0769), Performs well on metrics ({'converged': True, 'iters': 13, 'combined_score': 0.07692307692307693}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 13, 'eval_time': '20.735s'}), Performs well on formal_certification (Lean4_Auto_Proven)\n\n### Program 2 (Score: 0.0769)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n    # Adjust mu to decrease with iterations for finer convergence\n    # As k increases, mu approaches 1.0, making the condition stricter\n    # Start at mu and approach 1.0\n    adjusted_mu = 1.0 + (mu - 1.0) / (k + 1.0)\n    \n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Protect against division by zero\n    # Use max with eps only when necessary\n    r_protected = max(r_norm, eps)\n    s_protected = max(s_norm, eps)\n    \n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > adjusted_mu * s_protected:\n        new_rho = rho * (1.0 + t)\n        mode = \"mul\"\n\n    elif s_norm > adjusted_mu * r_protected:\n        new_rho = rho / (1.0 + t)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0769), Performs well on metrics ({'converged': True, 'iters': 13, 'combined_score': 0.07692307692307693}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 13, 'eval_time': '21.544s'}), Performs well on formal_certification (Lean4_Auto_Proven)\n\n### Program 3 (Score: 0.0417)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence with faster initial decay.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    # Add a small constant to prevent division by zero\n    # Adjust to decay faster initially\n    return c / ((k + 2.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Enhanced direction logic with balanced thresholds\n    # Compute ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # More nuanced update conditions\n    if ratio > mu:\n        # Increase rho more aggressively when r_norm is much larger\n        new_rho = rho * (1.0 + 2.0 * t)\n        mode = \"mul\"\n        aux = ratio  # Store the ratio for information\n\n    elif ratio < 1.0 / mu:\n        # Decrease rho more aggressively when s_norm is much larger\n        new_rho = rho / (1.0 + 2.0 * t)\n        mode = \"div\"\n        aux = ratio\n\n    else:\n        # Keep rho but adjust slightly towards balance\n        # Small adjustment based on which residual is larger\n        if r_norm > s_norm:\n            new_rho = rho * (1.0 + 0.5 * t)\n            mode = \"adjust_up\"\n        elif s_norm > r_norm:\n            new_rho = rho / (1.0 + 0.5 * t)\n            mode = \"adjust_down\"\n        else:\n            new_rho = rho\n            mode = \"keep\"\n        aux = ratio\n\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0417), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.041666666666666664}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '24.987s'}), Performs well on formal_certification (Lean4_Not_Auto_Proven)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0385)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with dynamic threshold.\n\n    More aggressive updates for faster convergence.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n    \n    # Dynamic mu that decreases with iterations to become more sensitive\n    # Start with mu and reduce it gradually\n    dynamic_mu = mu / (1.0 + 0.1 * k)\n    \n    # Determine update direction\n    if r_norm > dynamic_mu * max(s_norm, eps):\n        new_rho = rho * (1.0 + t)\n        mode = \"mul\"\n    elif s_norm > dynamic_mu * max(r_norm, eps):\n        new_rho = rho / (1.0 + t)\n        mode = \"div\"\n    else:\n        # When residuals are balanced, make a small adjustment based on their ratio\n        # This can help fine-tune convergence\n        if r_norm > s_norm:\n            # r_norm is slightly larger, increase rho slightly\n            new_rho = rho * (1.0 + 0.5 * t)\n            mode = \"small_mul\"\n        elif s_norm > r_norm:\n            # s_norm is slightly larger, decrease rho slightly\n            new_rho = rho / (1.0 + 0.5 * t)\n            mode = \"small_div\"\n        else:\n            new_rho = rho\n            mode = \"keep\"\n    \n    # Auxiliary scalar: track the adjustment factor\n    aux = t\n    \n    return new_rho, aux, mode\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0769, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n    # Adjust mu to decrease with iterations for finer convergence\n    # As k increases, mu approaches 1.0, making the condition stricter\n    # Start at mu and approach 1.0\n    adjusted_mu = 1.0 + (mu - 1.0) / (k + 1.0)\n    \n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Protect against division by zero\n    # Use max with eps only when necessary\n    r_protected = max(r_norm, eps)\n    s_protected = max(s_norm, eps)\n    \n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > adjusted_mu * s_protected:\n        new_rho = rho * (1.0 + t)\n        mode = \"mul\"\n\n    elif s_norm > adjusted_mu * r_protected:\n        new_rho = rho / (1.0 + t)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 2 (Score: 0.0385, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule with dynamic threshold.\n\n    More aggressive updates for faster convergence.\n    \"\"\"\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n    \n    # Dynamic mu that decreases with iterations to become more sensitive\n    # Start with mu and reduce it gradually\n    dynamic_mu = mu / (1.0 + 0.1 * k)\n    \n    # Determine update direction\n    if r_norm > dynamic_mu * max(s_norm, eps):\n        new_rho = rho * (1.0 + t)\n        mode = \"mul\"\n    elif s_norm > dynamic_mu * max(r_norm, eps):\n        new_rho = rho / (1.0 + t)\n        mode = \"div\"\n    else:\n        # When residuals are balanced, make a small adjustment based on their ratio\n        # This can help fine-tune convergence\n        if r_norm > s_norm:\n            # r_norm is slightly larger, increase rho slightly\n            new_rho = rho * (1.0 + 0.5 * t)\n            mode = \"small_mul\"\n        elif s_norm > r_norm:\n            # s_norm is slightly larger, decrease rho slightly\n            new_rho = rho / (1.0 + 0.5 * t)\n            mode = \"small_div\"\n        else:\n            new_rho = rho\n            mode = \"keep\"\n    \n    # Auxiliary scalar: track the adjustment factor\n    aux = t\n    \n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 3 (Score: 0.0417, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence with faster initial decay.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    # Add a small constant to prevent division by zero\n    # Adjust to decay faster initially\n    return c / ((k + 2.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Enhanced direction logic with balanced thresholds\n    # Compute ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # More nuanced update conditions\n    if ratio > mu:\n        # Increase rho more aggressively when r_norm is much larger\n        new_rho = rho * (1.0 + 2.0 * t)\n        mode = \"mul\"\n        aux = ratio  # Store the ratio for information\n\n    elif ratio < 1.0 / mu:\n        # Decrease rho more aggressively when s_norm is much larger\n        new_rho = rho / (1.0 + 2.0 * t)\n        mode = \"div\"\n        aux = ratio\n\n    else:\n        # Keep rho but adjust slightly towards balance\n        # Small adjustment based on which residual is larger\n        if r_norm > s_norm:\n            new_rho = rho * (1.0 + 0.5 * t)\n            mode = \"adjust_up\"\n        elif s_norm > r_norm:\n            new_rho = rho / (1.0 + 0.5 * t)\n            mode = \"adjust_down\"\n        else:\n            new_rho = rho\n            mode = \"keep\"\n        aux = ratio\n\n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n# Current Program\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size sequence.\n\n    Requirements:\n    - tau_k >= 0\n    - summable for p > 1\n    - depends only on k and fixed constants\n    \"\"\"\n    return c / ((k + 1.0) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > mu * max(s_norm, eps):\n        new_rho = rho * (1.0 + t)\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        new_rho = rho / (1.0 + t)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Looking at the current program, it has a fitness score of 0.0769, which matches the top-performing programs. However, the system values diversity across features, and the current program is very similar to Program 1. To potentially improve fitness while introducing diversity, I notice that the current program uses a fixed `mu` threshold, while some other programs adjust `mu` over iterations.\n\nThe top-performing Program 2 uses an adjusted mu that decreases with iterations: `adjusted_mu = 1.0 + (mu - 1.0) / (k + 1.0)`. This makes the condition stricter as iterations progress, which could lead to better convergence. However, it's important to note that both Program 1 and Program 2 have the same fitness score (0.0769), so this change may not improve fitness but could add diversity.\n\nBut wait, the current program's fitness is 0.0769, which is already good. However, the history shows that Attempt 3 (which was more complex) regressed to 0.0417. So we need to be careful not to overcomplicate.\n\nAnother observation: the current program uses `max(s_norm, eps)` and `max(r_norm, eps)` in the conditions, which is fine. However, we can make the update more balanced by using a symmetric approach to avoid bias.\n\nLet's consider a modification that adds a small adjustment when residuals are nearly balanced, but not enough to trigger the main conditions. This could help fine-tune convergence without being too aggressive. However, we must ensure the auxiliary scalar `aux` remains independent of residuals to satisfy C1-safety.\n\nLooking at the diverse program D1, it adds small adjustments when residuals are balanced, but its fitness is lower (0.0385). So that's not good.\n\nPerhaps we can try a hybrid approach: use the adjusted mu from Program 2, but keep the rest simple. Since Program 2 has the same fitness, this might maintain fitness while adding diversity.\n\nBut the system might value diversity in complexity. The current program is simple, so making it slightly more complex could be beneficial.\n\nLet's implement the adjusted mu approach, but ensure the code remains clear and concise.\n\nHere's the change:\n\n<<<<<<< SEARCH\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design.\n    \"\"\"\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > mu * max(s_norm, eps):\n        new_rho = rho * (1.0 + t)\n        mode = \"mul\"\n\n    elif s_norm > mu * max(r_norm, eps):\n        new_rho = rho / (1.0 + t)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n=======\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    C1-safe adaptive ADMM penalty update rule.\n\n    Conservative by design with adaptive threshold.\n    \"\"\"\n    # Adjust mu to become stricter as iterations increase\n    # This helps in finer convergence control\n    adjusted_mu = 1.0 + (mu - 1.0) / (k + 1.0)\n\n    # Summable step size (independent of residuals)\n    t = tau(k, c, p)\n\n    # Direction logic ONLY (may depend on residuals)\n    if r_norm > adjusted_mu * max(s_norm, eps):\n        new_rho = rho * (1.0 + t)\n        mode = \"mul\"\n\n    elif s_norm > adjusted_mu * max(r_norm, eps):\n        new_rho = rho / (1.0 + t)\n        mode = \"div\"\n\n    else:\n        new_rho = rho\n        mode = \"keep\"\n\n    # Auxiliary scalar: purely tau_k (no residual dependence)\n    aux = t\n\n    return new_rho, aux, mode\n>>>>>>> REPLACE\n\nThis change introduces an adaptive threshold that becomes stricter over iterations, which could potentially improve convergence behavior. Since Program 2 uses this approach and has the same fitness score, it's likely safe. Moreover, it adds diversity in the complexity dimension by introducing a dynamic adjustment.\n\nAdditionally, we can consider making a small change to the tau function to see if it affects performance, but since the top programs use the same tau, it's better to leave it unchanged.\n\nLet's also ensure the code length doesn't increase too much. The new code adds a few lines, but it's still within reasonable limits.\n\nThis modification maintains the C1-safety because the auxiliary scalar `aux` is still `t`, which is independent of residuals. The adjusted mu depends only on `k` and fixed constants, which is allowed.\n\nBy making this change, we hope to maintain or potentially improve the fitness score while adding a new feature coordinate (adaptive threshold) to increase diversity in the population."]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}